{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/db_loader.py\n",
    "!wget -q https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/llm_connector.py\n",
    "!wget -q https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/requirements.txt\n",
    "\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/Files/Demand%20Forecasting%20%26%20Rebalancing%20Planner.pdf\n",
    "!wget -q https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/Files/Network%20Expansion%20%26%20Capacity%20Sizing.pdf\n",
    "!wget -q https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/Files/Station%20Availability%20%26%20SLA%20Monitoring.pdf\n",
    "!wget -q https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/Files/Weather-Aware%20Rider%20Incentives.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c422546",
   "metadata": {},
   "source": [
    "# Sample PRDs\n",
    "\n",
    "1. **Station Availability & SLA Monitoring**\n",
    "    1. **Purpose:** Detect and prevent “empty/full” station outages with live alerts, on-call rotations, and an ops dashboard.\n",
    "    2. **Key inputs:** `status` (bikes/docks by timestamp), `station` (location, capacity).**Primary KPIs:** % time stations are in-service (not empty/full), mean time to recover (MTTR), alerts per 10k trips.\n",
    "2. **Demand Forecasting & Rebalancing Planner**\n",
    "    1. **Purpose:** Forecast hourly net inflow/outflow per station and generate shift plans/van routes to keep supply balanced.\n",
    "    2. **Key inputs:** `trip` (start/end, duration), `status` (historical fill curves), `weather` (temp, rain, wind), `station` (dock_count, lat/long).\n",
    "    3. **Primary KPIs:** Stockout minutes ↓, rebalancing cost/ride ↓, forecast MAE per station-hour.\n",
    "3. **Weather-Aware Rider Incentives (Crowd Rebalancing)**\n",
    "    1. **Purpose:** Issue targeted credits to riders to pick up/return at stressed stations when forecasted load or live status crosses thresholds.\n",
    "    2. **Key inputs:** `status` (live stress), `trip` (origin/destination patterns), `weather` (event-sensitive demand), `station` (capacity, proximity graph).\n",
    "    3. **Primary KPIs:** % stress events resolved via incentives, incentive cost per resolved event, availability uplift vs. control.\n",
    "4. **Network Expansion & Capacity Sizing**\n",
    "    1. **Purpose:** Identify where to add docks/new stations by modeling unmet demand, churn from outages, and micro-mobility catchment gaps.\n",
    "    2. **Key inputs:** `trip` (OD flows, overflow durations), `status` (chronic empty/full streaks), `station` (geo features), `weather` (seasonality).\n",
    "    3. **Primary KPIs:** Incremental rides at proposed sites, reduction in nearby stockouts, ROI (rides/$ of infrastructure).\n",
    "\n",
    "# PRDs:\n",
    "\n",
    "[Station Availability & SLA Monitoring](https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/Files/Station%20Availability%20%26%20SLA%20Monitoring.pdf)\n",
    "\n",
    "[Demand Forecasting & Rebalancing Planner](https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/Files/Demand%20Forecasting%20%26%20Rebalancing%20Planner.pdf)\n",
    "\n",
    "[Weather-Aware Rider Incentives (Crowd Rebalancing)](https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/Files/Weather-Aware%20Rider%20Incentives.pdf)\n",
    "\n",
    "[Network Expansion & Capacity Sizing](https://raw.githubusercontent.com/alikarami76/genai-workshop/refs/heads/main/Files/Network%20Expansion%20%26%20Capacity%20Sizing.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e365f87",
   "metadata": {},
   "source": [
    "# PRD Writer Agent Workshop\n",
    "\n",
    "Welcome! In this workshop notebook we turn LangChain, Groq, and a Citi Bike SQLite dataset into a Product Requirements Document (PRD) co-pilot. The agent blends structured ride data with curated reference docs so product teams can articulate a commuter-pass concept—without leaving the notebook.\n",
    "\n",
    "You will guide learners through each layer of the stack: environment preparation, safe SQL tooling, document retrieval, prompting, and live execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7523962",
   "metadata": {},
   "source": [
    "## Why we rely on Markdown for model context\n",
    "\n",
    "> Markdown sits closest to the code, version controls cleanly, and renders everywhere our learners will review the notebook.\n",
    "\n",
    "| Context method | Benefits | Drawbacks |\n",
    "| --- | --- | --- |\n",
    "| Markdown cells (this notebook) | Sits inline with execution order; easy to diff and iterate; visible during live teaching. | Requires deliberate authoring effort. |\n",
    "| Inline code comments | Great for pointing at specific lines, but disappear during demo runs and clutter logic. | Hard for non-coders to follow; limited formatting. |\n",
    "| External docs / slides | Rich visuals, but easily fall out of sync with the live notebook. | Context switching interrupts the teaching flow. |\n",
    "\n",
    "Markdown wins because it keeps narrative, prompts, and outputs co-located. Learners can rerun the notebook later and still have the story stitched right next to the cells the model reads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f657b8",
   "metadata": {},
   "source": [
    "## Environment setup & context anchors\n",
    "\n",
    "The next cell imports every library our agent touches—from standard utilities and pandas to LangChain prompt builders. Call out that keeping imports explicit helps models (and humans) understand the available tools, which is essential when you later ask ChatGPT to extend the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e2f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install dependencies (uncomment if needed)\n",
    "\n",
    "import os, re, glob, json, time, sqlite3, textwrap\n",
    "from typing import Optional, List, Dict, Any, Literal\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain / Groq\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# markitdown converts many file formats into Markdown\n",
    "from markitdown import MarkItDown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d50cc5",
   "metadata": {},
   "source": [
    "## Configure the Groq LLM for PRD drafting\n",
    "\n",
    "We obtain a Groq-hosted `moonshotai/kimi-k2-instruct-0905` model through a helper. The `.bind(...)` call is where we could control sampling behavior:\n",
    "- `top_p=1` (if set) keeps the nucleus wide; lowering it or explicitly setting `top_k` would make the model hug the most likely continuations.\n",
    "- `temperature` is omitted here, so the connector default applies. Encourage learners to experiment with lower values (~0.2) when they want reproducible PRD sections.\n",
    "- `max_completion_tokens` bounds response length so the agent cannot ramble indefinitely.\n",
    "\n",
    "Even when some knobs are commented out, pointing to them during the workshop shows participants which levers they can pull when they need more determinism or richer reasoning effort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_connector import langchain_groq_llm_connector\n",
    "\n",
    "llm = langchain_groq_llm_connector(\"Insert API Key Here\",\"openai/gpt-oss-20b\")\n",
    "llm = llm.bind(\n",
    "    tools=[{\"type\":\"browser_search\"},{\"type\":\"code_interpreter\"}],\n",
    "    compound_custom = {\"tools\":{\"enabled_tools\":[\"web_search\",\"code_interpreter\"]}},\n",
    "    tool_choice=\"auto\",\n",
    "    reasoning_effort=\"medium\",\n",
    "    top_p=1,\n",
    "    max_completion_tokens=8192,\n",
    ")\n",
    "\n",
    "\n",
    "# ---- Safety knobs for SQL and results ----------------------------------------\n",
    "SQL_TIMEOUT_SECONDS = 5000      # wall clock per query\n",
    "SQL_MAX_RETURN_ROWS = 10000000   # cap result rows to avoid huge pulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388fe08f",
   "metadata": {},
   "source": [
    "## Link the SQL knowledge base\n",
    "\n",
    "This cell anchors the Retrieval-Augmented Generation (RAG) pipeline to a consistent data source. We reuse the Citi Bike SQLite path so the agent can fact-check PRD claims—like subscriber distribution or commuter trip volumes—directly from historical rides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd195ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_loader import prepare_citibike_database\n",
    "\n",
    "DB_PATH, conn, run_query = prepare_citibike_database()\n",
    "SQLITE_URI = f\"sqlite:///{DB_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd12ad",
   "metadata": {},
   "source": [
    "## Guarded SQL tool overview\n",
    "\n",
    "Before letting the agent touch data, we wrap SQLite access in helper functions that enforce read-only behavior, inject `LIMIT` clauses, and store results on disk. Emphasize that:\n",
    "- `_is_read_only` and `_add_limit_if_missing` are defensive coding patterns students should reuse when exposing databases to LLMs.\n",
    "- The `@tool`-decorated `run_sqlite_query` returns JSON metadata (paths, preview Markdown, executed SQL) so downstream tools—and the agent—can chain work predictably.\n",
    "\n",
    "This design keeps the notebook safe for live demos, even when learners craft creative prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a43940",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _is_read_only(sql: str) -> bool:\n",
    "    \"\"\"Allow only SELECT and PRAGMA table_info (read-only).\"\"\"\n",
    "    forbidden = r\"\\b(INSERT|UPDATE|DELETE|DROP|ALTER|CREATE|REPLACE|TRUNCATE|ATTACH|DETACH|VACUUM|BEGIN|COMMIT)\\b\"\n",
    "    if re.search(forbidden, sql, flags=re.IGNORECASE):\n",
    "        return False\n",
    "    if re.search(r\"\\bPRAGMA\\b\", sql, re.IGNORECASE) and \"table_info\" not in sql.lower():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _add_limit_if_missing(sql: str, limit: int) -> str:\n",
    "    \"\"\"Inject a LIMIT if the user didn't specify one on SELECT queries.\"\"\"\n",
    "    q = sql.strip().rstrip(\";\")\n",
    "    if not q.lower().startswith(\"select\"):\n",
    "        return q + \";\"\n",
    "    if re.search(r\"\\blimit\\b\", q, flags=re.IGNORECASE):\n",
    "        return q + \";\"\n",
    "    return f\"SELECT * FROM (\\n{q}\\n) LIMIT {limit};\"\n",
    "\n",
    "@tool(\"run_sqlite_query\", return_direct=False)\n",
    "def run_sqlite_query(query: str, limit: int = SQL_MAX_RETURN_ROWS) -> str:\n",
    "    \"\"\"\n",
    "    Run a read-only SQL query against the local SQLite DB.\n",
    "    Safety: Only SELECT or PRAGMA table_info allowed. LIMIT injected if missing for SELECT.\n",
    "    Returns a small JSON string with file paths and a preview table.\n",
    "    \"\"\"\n",
    "    if DB_PATH is None or not os.path.exists(DB_PATH):\n",
    "        return json.dumps({\"error\": \"No SQLite database found. Set DB_FILENAME or place a .sqlite/.db in this folder.\"})\n",
    "    if not _is_read_only(query):\n",
    "        return json.dumps({\"error\": \"Only read-only queries allowed (SELECT/PRAGMA table_info).\"})\n",
    "    if query.strip().lower().startswith(\"select\") and \"limit\" not in query.lower():\n",
    "        query = _add_limit_if_missing(query, limit)\n",
    "    conn = sqlite3.connect(DB_PATH, check_same_thread=False)\n",
    "    conn.execute(f\"PRAGMA busy_timeout = {SQL_TIMEOUT_SECONDS*1000};\")\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"SQLite error: {e}\"})\n",
    "    finally:\n",
    "        conn.close()\n",
    "    csv_path = os.path.join(\"outputs\", \"sql_result.csv\")\n",
    "    json_path = os.path.join(\"outputs\", \"sql_result.json\")\n",
    "    try:\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        df.to_json(json_path, orient=\"records\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        preview_md = df.head(10).to_markdown(index=False) if not df.empty else \"(no rows)\"\n",
    "    except Exception:\n",
    "        preview_md = df.head(10).to_string(index=False) if not df.empty else \"(no rows)\"\n",
    "    return json.dumps({\n",
    "        \"rows\": int(len(df)),\n",
    "        \"columns\": list(map(str, df.columns)),\n",
    "        \"csv_path\": csv_path,\n",
    "        \"json_path\": json_path,\n",
    "        \"preview\": preview_md,\n",
    "        \"sql_used\": query,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0394508",
   "metadata": {},
   "source": [
    "## Document context builder (markitdown + BM25)\n",
    "\n",
    "The upcoming cell introduces a complementary tool that turns slides, PDFs, and spreadsheets into retrievable context. Highlight how we:\n",
    "- Accept both `build` (index documents) and `search` (retrieve top chunks) modes through a typed Pydantic schema.\n",
    "- Use `markitdown` to convert rich formats into Markdown, keeping structure that the LLM can ingest easily.\n",
    "- Apply a BM25 retriever so queries surface the most relevant passages for the PRD draft.\n",
    "\n",
    "Together with the SQL tool, this rounds out both halves of RAG: structured data plus unstructured reference material.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_EXT = {\".pdf\", \".ppt\", \".pptx\", \".xls\", \".xlsx\", \".png\", \".jpg\", \".jpeg\"}\n",
    "\n",
    "class DocContextArgs(BaseModel):\n",
    "    mode: Literal[\"build\", \"search\"] = Field(..., description=\"'build' to index a folder; 'search' to retrieve relevant chunks.\")\n",
    "    directory: Optional[str] = Field(None, description=\"Directory path containing source documents (for build mode).\")\n",
    "    query: Optional[str] = Field(None, description=\"Search query (for search mode).\")\n",
    "    top_k: int = Field(5, description=\"Number of chunks to return in search mode.\")\n",
    "\n",
    "_CURRENT_INDEX_NAME: Optional[str] = None\n",
    "_CURRENT_RETRIEVER: Optional[BM25Retriever] = None\n",
    "_CURRENT_CHUNKS: List[Document] = []\n",
    "\n",
    "def _collect_files(root_dir: str) -> List[str]:\n",
    "    files: List[str] = []\n",
    "    for base, _, fnames in os.walk(root_dir):\n",
    "        for f in fnames:\n",
    "            ext = os.path.splitext(f)[1].lower()\n",
    "            if ext in ALLOWED_EXT:\n",
    "                files.append(os.path.join(base, f))\n",
    "    return files\n",
    "\n",
    "def _md_from_file(md: MarkItDown, path: str) -> str:\n",
    "    try:\n",
    "        result = md.convert(path)\n",
    "        text = result.text if hasattr(result, \"text\") else str(result)\n",
    "        return text or \"\"\n",
    "    except Exception as e:\n",
    "        return f\"[markitdown error reading {os.path.basename(path)}: {e}]\"\n",
    "\n",
    "@tool(\"doc_context\", args_schema=DocContextArgs, return_direct=False)\n",
    "def doc_context(mode: str, directory: Optional[str] = None, query: Optional[str] = None, top_k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Document context builder and retriever using markitdown + BM25.\n",
    "    mode=build: index a folder of PDFs, PPT(X), XLS(X), PNG/JPG into Markdown chunks.\n",
    "    mode=search: retrieve top-k relevant chunks from the last-built index.\n",
    "    Returns JSON with index summary or match snippets.\n",
    "    \"\"\"\n",
    "    global _CURRENT_INDEX_NAME, _CURRENT_RETRIEVER, _CURRENT_CHUNKS\n",
    "    if mode == \"build\":\n",
    "        if not directory:\n",
    "            return json.dumps({\"error\": \"Provide 'directory' for build mode.\"})\n",
    "        if not os.path.isdir(directory):\n",
    "            return json.dumps({\"error\": f\"Directory not found: {directory}\"})\n",
    "        files = _collect_files(directory)\n",
    "        if not files:\n",
    "            return json.dumps({\"error\": f\"No supported files found under: {directory}\"})\n",
    "        mkd = MarkItDown()\n",
    "        docs: List[Document] = []\n",
    "        for fp in files:\n",
    "            md_text = _md_from_file(mkd, fp)\n",
    "            docs.append(Document(page_content=md_text, metadata={\"source\": fp}))\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=150)\n",
    "        chunks = splitter.split_documents(docs)\n",
    "        retriever = BM25Retriever.from_documents(chunks)\n",
    "        retriever.k = 6\n",
    "        _CURRENT_INDEX_NAME = os.path.abspath(directory)\n",
    "        _CURRENT_RETRIEVER = retriever\n",
    "        _CURRENT_CHUNKS = chunks\n",
    "        summary = {\n",
    "            \"indexed_dir\": _CURRENT_INDEX_NAME,\n",
    "            \"file_count\": len(files),\n",
    "            \"chunk_count\": len(chunks),\n",
    "            \"sample_files\": [os.path.basename(p) for p in files[:5]],\n",
    "        }\n",
    "        return json.dumps(summary)\n",
    "    elif mode == \"search\":\n",
    "        if _CURRENT_RETRIEVER is None:\n",
    "            return json.dumps({\"error\": \"No index built yet. Call doc_context with mode='build' first.\"})\n",
    "        if not query:\n",
    "            return json.dumps({\"error\": \"Provide 'query' for search mode.\"})\n",
    "        _CURRENT_RETRIEVER.k = max(1, min(int(top_k), 20))\n",
    "        results = _CURRENT_RETRIEVER.get_relevant_documents(query)\n",
    "        def to_snippet(d: Document) -> Dict[str, Any]:\n",
    "            txt = d.page_content.replace(\"\\n\", \" \")\n",
    "            snippet = (txt[:400] + \"...\") if len(txt) > 400 else txt\n",
    "            return {\"source\": os.path.basename(d.metadata.get(\"source\", \"unknown\")), \"snippet\": snippet}\n",
    "        out = {\n",
    "            \"indexed_dir\": _CURRENT_INDEX_NAME,\n",
    "            \"query\": query,\n",
    "            \"top_k\": _CURRENT_RETRIEVER.k,\n",
    "            \"matches\": [to_snippet(d) for d in results],\n",
    "        }\n",
    "        return json.dumps(out)\n",
    "    else:\n",
    "        return json.dumps({\"error\": \"Unknown mode. Use 'build' or 'search'.\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28205e55",
   "metadata": {},
   "source": [
    "### RAG workflow cheat sheet\n",
    "\n",
    "> Retrieve from SQL **and** documents, then generate the PRD narrative.\n",
    "\n",
    "1. **Indexing** – Convert docs to Markdown and store BM25 vectors.\n",
    "2. **Query planning** – Agent decides whether it needs SQL metrics, document insights, or both.\n",
    "3. **Retrieval** – `run_sqlite_query` returns tables; `doc_context` returns annotated excerpts.\n",
    "4. **Synthesis** – The LLM weaves retrieved facts into PRD sections.\n",
    "\n",
    "- [x] Structured data captured (SQLite)\n",
    "- [x] Unstructured context captured (Docs folder)\n",
    "- [ ] Manual copy/paste (no longer required!)\n",
    "\n",
    "| Stage | Tool/Prompt | Output |\n",
    "| --- | --- | --- |\n",
    "| 1 | `doc_context` in `build` mode | Indexed Markdown corpus |\n",
    "| 2 | Agent PLAN (Thought steps) | Tool call decisions |\n",
    "| 3 | `run_sqlite_query` + `doc_context` (`search`) | JSON payloads w/ data + excerpts |\n",
    "| 4 | LLM completion under system prompt | Polished PRD Markdown |\n",
    "\n",
    "```text\n",
    "[User Brief]\n",
    "    ↓\n",
    "(System Prompt + PLAN)\n",
    "    ↓\n",
    "[SQL Tool] → metrics.csv/json\n",
    "[Doc Tool] → supporting excerpts\n",
    "    ↓\n",
    "      LLM synthesizes PRD\n",
    "```\n",
    "\n",
    "Markdown gives us flexible visuals—lists, tables, ASCII diagrams—that render perfectly in Jupyter and keep the retrieval story close to the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f82a1",
   "metadata": {},
   "source": [
    "## PRD system prompt guidance\n",
    "\n",
    "This prompt is the agent’s **prefix** message: it persists across turns and overrides conflicting user instructions. Walk learners through best practices evident here:\n",
    "- Scope the mission (“produce a clear, complete PRD”) and constrain data sources.\n",
    "- Include explicit refusal guidance to prevent hallucinated facts.\n",
    "- Call out output formatting expectations (Markdown headings, tables, bullet points) so downstream audiences can read the draft immediately.\n",
    "\n",
    "Encourage participants to keep system prompts directive, modular (use lists over paragraphs), and transparent about tone and structure. That way, user prompts can stay concise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082313f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRD_SYSTEM_PROMPT = textwrap.dedent(\n",
    "    \"\"\"\n",
    "    You are a meticulous Product Requirements Document (PRD) writer.\n",
    "    Your job is to produce a clear, complete PRD in Markdown using ONLY information derived from:\n",
    "      - SQL research via the provided SQLite tool, and\n",
    "      - Document context provided via the document context tool.\n",
    "\n",
    "    Do not fabricate facts or numbers. If information is unavailable, mark it clearly as a gap.\n",
    "    Always call tools when you need data or supporting context.\n",
    "    Reference the documents that you have used in a \"Sources\" section at the end. Also tag which parts have used which references in the footnote.\n",
    "\n",
    "    OUTPUT FORMAT (Markdown, in this exact order):\n",
    "    # <Product Name>\n",
    "    \n",
    "    ## Summary\n",
    "    - One–two sentence overview of the product and its value.\n",
    "    - Who benefits and in what scenario.\n",
    "    \n",
    "    ## Goals\n",
    "    - Goal 1\n",
    "    - Goal 2\n",
    "    \n",
    "    ## Non-Goals\n",
    "    - Explicitly list what is out of scope.\n",
    "    \n",
    "    ## Background\n",
    "    - Problem statement and context.\n",
    "    - Key constraints, assumptions, and dependencies (cite sources).\n",
    "    \n",
    "    ## Target Users & Personas\n",
    "    - Persona(s) with brief needs and pain points.\n",
    "    \n",
    "    ## Use Cases\n",
    "    - Use case 1: short description.\n",
    "    - Use case 2: short description.\n",
    "    \n",
    "    ## Functional Requirements\n",
    "    | ID | Requirement | Priority | Acceptance Criteria |\n",
    "    |----|-------------|----------|---------------------|\n",
    "    | FR-1 | ... | P0/P1/P2 | Concrete, testable criteria |\n",
    "    | FR-2 | ... | P0/P1/P2 | Concrete, testable criteria |\n",
    "    \n",
    "    ## Expected Behavior\n",
    "    Describe key flows as scenarios in a table.\n",
    "    | Scenario | Given | When | Then |\n",
    "    |----------|-------|------|------|\n",
    "    | Example | Starting context | Action taken | Expected result |\n",
    "    \n",
    "    ## Edge Cases & Error Handling\n",
    "    - How the feature interacts with core functionalities.\n",
    "    - How the interaction between this feature and other features is handled.\n",
    "\n",
    "    ## UX & Platform Considerations\n",
    "    - Platforms, accessibility, localization, performance notes.\n",
    "    \n",
    "    ## Data & Analytics\n",
    "    - Key metrics, events to track, and success criteria.\n",
    "    - Include any SQL used for metric definitions in a fenced code block.\n",
    "    \n",
    "    ## Risks & Open Questions\n",
    "    - Risk 1 and mitigation.\n",
    "    - Open question 1.\n",
    "    \n",
    "    ## Milestones (Optional)\n",
    "    - Rough phases and dates if available.\n",
    "    \n",
    "    ## Sources\n",
    "    - List document filenames and/or a short description of SQL datasets used.\n",
    "\n",
    "    TOOL USAGE GUIDELINES:\n",
    "    - Use `doc_context` in mode=\"build\" once to index the user-provided folder before drafting.\n",
    "    - Use `doc_context` in mode=\"search\" whenever you need supporting context.\n",
    "    - Use `run_sqlite_query` for quantitative data; show SQL in the PRD where relevant.\n",
    "    - If a tool returns an error or there is insufficient context, state the gap explicitly in the PRD.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Keep responses concise and factual; do not include chain-of-thought.\n",
    "    - Do not assume file paths or database schema beyond tool results.\n",
    "    - Always produce valid Markdown matching the structure above.\n",
    "    \"\"\"\n",
    ").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b69694",
   "metadata": {},
   "source": [
    "## Agent wiring and control knobs\n",
    "\n",
    "Here we assemble the LangChain `ChatPromptTemplate`, plug in both tools, and wrap everything with `AgentExecutor`.\n",
    "- `MessagesPlaceholder(\"agent_scratchpad\")` captures intermediate Thought/Action/Observation traces, making the agent explainable in workshops.\n",
    "- `max_iterations=8` is the guardrail that complements `top_p`/`temperature`: it caps how many tool calls the agent may attempt before stopping.\n",
    "- `handle_parsing_errors=True` keeps the session resilient if the LLM emits a slightly malformed JSON chunk.\n",
    "\n",
    "Link these settings back to earlier discussions about controlling creativity and determinism—prompting is only half the story; runtime limits complete the toolkit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", PRD_SYSTEM_PROMPT),\n",
    "    (\"human\", \"PRD outline: {prd_outline}\\n\\nIf you need documents, index directory: {docs_dir}\\nProceed.\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "TOOLS = [run_sqlite_query, doc_context]\n",
    "\n",
    "# Try to bind tools to the model for better compatibility; fall back if unavailable\n",
    "try:\n",
    "    llm_for_agent = llm.bind_tools(TOOLS)\n",
    "except Exception:\n",
    "    llm_for_agent = llm\n",
    "\n",
    "# Build the tool-calling agent\n",
    "agent_runnable = create_tool_calling_agent(llm_for_agent, TOOLS, PROMPT)\n",
    "\n",
    "# Construct executor with version-compatible kwargs\n",
    "try:\n",
    "    executor = AgentExecutor(\n",
    "        agent=agent_runnable,\n",
    "        tools=TOOLS,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "        max_iterations=20,\n",
    "        handle_parsing_errors=True,\n",
    "    )\n",
    "except TypeError:\n",
    "    # Fallback for older AgentExecutor that doesn't accept handle_parsing_errors\n",
    "    executor = AgentExecutor(\n",
    "        agent=agent_runnable,\n",
    "        tools=TOOLS,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "        max_iterations=20,\n",
    "    )\n",
    "\n",
    "print(\"PRD Agent ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8e496",
   "metadata": {},
   "source": [
    "## Run helper utility\n",
    "\n",
    "`run_prd_writer` orchestrates a full pass end-to-end: it optionally builds the document index, runs the agent, and captures both the final PRD and intermediate artifacts. Stress how pre-building the index reduces latency during live demos and how saving outputs to `outputs/` gives students artifacts to review after class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ea676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prd_writer(prd_outline: str, docs_dir: Optional[str] = None) -> Dict[str, Any]:\n",
    "    # Optionally build the doc index up-front to help the agent\n",
    "    try:\n",
    "        if docs_dir and os.path.isdir(docs_dir):\n",
    "            _ = doc_context.invoke({\n",
    "                \"mode\": \"build\",\n",
    "                \"directory\": docs_dir,\n",
    "                \"query\": None,\n",
    "                \"top_k\": 5,\n",
    "            })\n",
    "    except Exception:\n",
    "        pass\n",
    "    inputs = {\"prd_outline\": prd_outline, \"docs_dir\": docs_dir or \"(none provided)\"}\n",
    "    return executor.invoke(inputs)\n",
    "\n",
    "def save_markdown(md_text: str, out_path: Optional[str] = None) -> str:\n",
    "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    final_path = out_path or os.path.join(\"outputs\", f\"prd_{ts}.md\")\n",
    "    os.makedirs(os.path.dirname(final_path), exist_ok=True)\n",
    "    with open(final_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(md_text)\n",
    "    return final_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3796bd",
   "metadata": {},
   "source": [
    "## Example invocation & commuter-pass focus\n",
    "\n",
    "We seed the agent with a commuter-pass outline and point it at the shared documents directory. During the workshop you can:\n",
    "- Swap in different outlines (e.g., targeting weekend riders) and compare results.\n",
    "- Show how retrieved SQL metrics and document excerpts appear in the agent trace.\n",
    "- Emphasize that the final Markdown can be copied straight into a PRD template or product wiki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your outline and optional docs directory, then run.\n",
    "prd_outline = \"Write a PRD for a commuter pass feature where we offer passes for a certain origin-destation station combination valid for a month in exchange for a flat fee for non-subscribers at a cheaper price compared to the subscription.\"\n",
    "docs_dir = \"/content\"\n",
    "\n",
    "result = run_prd_writer(prd_outline, docs_dir)\n",
    "output_text = result.get(\"output\", \"\") if isinstance(result, dict) else str(result)\n",
    "print(output_text[:1000] + (\"...\" if len(output_text) > 1000 else \"\"))\n",
    "\n",
    "if output_text:\n",
    "    path = save_markdown(output_text)\n",
    "    print(f\"Saved PRD to: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c751c",
   "metadata": {},
   "source": [
    "## Sandbox cell for live exploration\n",
    "\n",
    "Use the final empty cell to experiment in front of learners—inspect saved Markdown files, tweak prompts, or prototype follow-up utilities—without disrupting the main workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ae2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
